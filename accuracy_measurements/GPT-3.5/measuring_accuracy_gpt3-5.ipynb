{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import setup\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=setup.openai_api_key, organization=setup.openai_organization_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(folder_name):\n",
    "  folder_names = os.listdir(folder_name)\n",
    "  # put all text in a list\n",
    "  text = []\n",
    "  for folder in folder_names:\n",
    "    with open(folder_name + '/' + folder + '/text.json') as file:\n",
    "      file_content = file.read()\n",
    "      file_content_str = json.loads(file_content)\n",
    "      # need to convert the file content to a dict to extract text\n",
    "      file_content_dict = json.loads(file_content_str)\n",
    "      text.append(file_content_dict[\"text\"])\n",
    "  return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "  text_prepros = []\n",
    "  for ex in text:\n",
    "    new1 = re.sub('\\n.+\\|thumb.*\\n?(.*)?', '', ex)\n",
    "    new2 = re.sub('\\n?(.*)?\\|thumb.*\\n', '', new1)\n",
    "    new3 = re.sub('\\n.+thumb\\|.*\\n?(.*)?', '', new2)\n",
    "    new4 = re.sub('\\n?(.*)?thumb\\|.*\\n', '', new3)\n",
    "    new5 = re.sub('\\n.+\\|thumbnail.*\\n?(.*)?', '', new4)\n",
    "    new6 = re.sub('\\n?(.*)?\\|thumbnail.*\\n', '', new5)\n",
    "    new7 = re.sub('\\n.+thumbnail\\|.*\\n?(.*)?', '', new6)\n",
    "    new8 = re.sub('\\n?(.*)?thumbnail\\|.*\\n', '', new7)\n",
    "    new9 = new8.lstrip(' ')\n",
    "    new10 = new9.lstrip('\\n')\n",
    "    text_prepros.append(new10)\n",
    "  folder_names = os.listdir(\"../../input_data/wikipedia_data_v3\")\n",
    "  ind = folder_names.index(\"Agriculture\")\n",
    "  text_prepros[ind] = text_prepros[ind].replace('\\nthumb |upright=1.35 |Centres of origin, as numbered by Nikolai Vavilov in the 1930s. Area 3 (gray) is no longer recognised as a centre of origin, and Papua New Guinea (area P, orange) was identified more recently.\\n', '')\n",
    "  rem1 = folder_names.index(\"AT&T_Plaza\")\n",
    "  del text_prepros[rem1]\n",
    "  rem2 = folder_names.index(\"Elgato\")\n",
    "  del text_prepros[rem2 - 1]\n",
    "  rem3 = folder_names.index(\"Engineer_boot\")\n",
    "  del text_prepros[rem3 - 2]\n",
    "  return text_prepros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text(\"../../input_data/wikipedia_data_v3\")\n",
    "text_clean = preprocess_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurement Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "def tokenize(enc, text_clean):\n",
    "    tokenized = []\n",
    "    for ex in text_clean:\n",
    "        encoding = enc.encode(ex)\n",
    "        tokenized.append(encoding)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_accuracy(example, filepath1_context, filepath2_topp):\n",
    "    with open(filepath1_context, 'w') as file:\n",
    "        json.dump({}, file)\n",
    "    with open(filepath2_topp, 'w') as file:\n",
    "        json.dump({}, file)\n",
    "    total_acc = 0\n",
    "    context_lengths = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 50, 75, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000]\n",
    "    for c in context_lengths:\n",
    "        example_dict = {}\n",
    "        top_p_predictions = {}\n",
    "        context_tokens = example[0:c]\n",
    "        context = enc.decode(context_tokens)\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": context}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=1,\n",
    "            logprobs=True,\n",
    "            top_logprobs=5\n",
    "        )\n",
    "        correct_string = enc.decode([example[c]])\n",
    "        stripped_correct_string = correct_string.strip()\n",
    "\n",
    "        predictions = response.choices[0].logprobs.content[0].top_logprobs\n",
    "        temp_top_pred = {}\n",
    "        for i in predictions:\n",
    "            temp_top_pred[i.logprob] = i.token\n",
    "        temp_top_pred_sorted = dict(sorted(temp_top_pred.items(), reverse=True))\n",
    "        top_words = list(temp_top_pred_sorted.values())\n",
    "        for e,(k,v) in enumerate(temp_top_pred_sorted.items()):\n",
    "            top_p_predictions['token_top_' + str(e+1)] = v\n",
    "            top_p_predictions['prob_top_' + str(e+1)] = k\n",
    "            if stripped_correct_string in top_words[0:e+1] or correct_string in top_words[0:e+1]:\n",
    "                top_p_predictions['accuracy_top_' + str(e+1)] = 1\n",
    "            else:\n",
    "                top_p_predictions['accuracy_top_' + str(e+1)] = 0\n",
    "        top_p_predictions['token_correct_stripped'] = stripped_correct_string\n",
    "        top_p_predictions['token_correct_not_stripped'] = correct_string\n",
    "\n",
    "        gpt_output = top_words[0]\n",
    "        accuracy_string = 0\n",
    "        if stripped_correct_string == gpt_output or correct_string == gpt_output:\n",
    "            accuracy_string = 1\n",
    "            total_acc += 1\n",
    "\n",
    "        example_dict[\"context\"] = context\n",
    "        example_dict[\"correct_string_not_stripped\"] = correct_string\n",
    "        example_dict[\"correct_token_not_stripped\"] = example[c]\n",
    "        example_dict[\"correct_string_stripped\"] = stripped_correct_string\n",
    "        example_dict[\"gpt_predicted_string\"] = gpt_output\n",
    "        example_dict[\"accuracy_string\"] = accuracy_string\n",
    "\n",
    "        with open(filepath1_context, \"r\") as file:\n",
    "            current = json.load(file)\n",
    "        current.update({c: example_dict})\n",
    "        with open(filepath1_context, \"w\") as file:\n",
    "            json.dump(current, file)\n",
    "\n",
    "        with open(filepath2_topp, \"r\") as file:\n",
    "            current = json.load(file)\n",
    "        current.update({c: top_p_predictions})\n",
    "        with open(filepath2_topp, \"w\") as file:\n",
    "            json.dump(current, file)\n",
    "\n",
    "    return total_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize(enc, text_clean)\n",
    "for i in range(0, 100):\n",
    "    ex = tokens[i]\n",
    "    accuracy = measure_accuracy(ex, 'output_context/gpt35context_ex' + str(i) + '.json', 'output_accuracies/gpt35topp_ex' + str(i) + '.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
